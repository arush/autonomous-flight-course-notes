1
00:00:00,000 --> 00:00:02,759
So, what can we do?

2
00:00:02,759 --> 00:00:06,150
A common thing to do when linear arising a nonlinear function,

3
00:00:06,150 --> 00:00:08,625
is to take the Taylor series approximation.

4
00:00:08,625 --> 00:00:11,820
The Taylor series approximation of H around

5
00:00:11,820 --> 00:00:16,289
the estimate is approximately equal to h of x hat naught,

6
00:00:16,289 --> 00:00:18,405
plus this matrix capital H,

7
00:00:18,405 --> 00:00:22,275
evaluated at h naught times x minus x hat naught,

8
00:00:22,274 --> 00:00:24,684
where capital Hx hat naught,

9
00:00:24,684 --> 00:00:28,049
is the first derivative of h evaluated at x hat naught.

10
00:00:28,050 --> 00:00:29,820
This should look similar to some of

11
00:00:29,820 --> 00:00:33,359
the linearization you did in the previous module on controls.

12
00:00:33,359 --> 00:00:35,729
Now if x and y are scalars,

13
00:00:35,729 --> 00:00:38,294
then the first derivative is a scalar itself.

14
00:00:38,295 --> 00:00:40,785
Hx naught is just a derivative,

15
00:00:40,784 --> 00:00:45,614
but if x and y are vectors of length n and m respectively,

16
00:00:45,615 --> 00:00:48,234
then you might remember from linear algebra that

17
00:00:48,234 --> 00:00:51,299
the first derivative is a matrix called the jacobian.

18
00:00:51,299 --> 00:00:54,459
Hx hat naught is equal to a matrix with

19
00:00:54,460 --> 00:00:59,024
the individual partial derivative components in the various locations in the matrix.

20
00:00:59,024 --> 00:01:02,445
Since we know both x hat naught and h,

21
00:01:02,445 --> 00:01:06,870
we can compute that jacobian and the function evaluated at the prior mean,

22
00:01:06,870 --> 00:01:11,055
which lets us rewrite all of this in a linear form A times x plus b,

23
00:01:11,055 --> 00:01:14,070
which is the form we need for a cursive estimation to work.

24
00:01:14,069 --> 00:01:19,679
As a result the maximum a posteriori algorithm is basically unchanged,

25
00:01:19,680 --> 00:01:22,080
with just an extra step of linearization,

26
00:01:22,079 --> 00:01:24,594
that is constructing the jacobian.

27
00:01:24,594 --> 00:01:27,590
Our three steps are now: One,

28
00:01:27,590 --> 00:01:32,325
construct the jacobian to get a linear approximation of h around the estimated state.

29
00:01:32,325 --> 00:01:35,295
Two, compute the posterior covariance.

30
00:01:35,295 --> 00:01:38,504
Three, compute the posterior mean estimate.

31
00:01:38,504 --> 00:01:43,429
You now have the ability to take in a series of measurements of an unknown quantity,

32
00:01:43,430 --> 00:01:46,605
where the measurements are non-linear function of the unknown quantity.

33
00:01:46,605 --> 00:01:49,109
Assuming that you have gaussian noise being

34
00:01:49,109 --> 00:01:52,304
injected into the system to perturb the measurements,

35
00:01:52,305 --> 00:01:55,665
you can still recover a reasonable estimate.

36
00:01:55,665 --> 00:01:58,680
This is exactly the process that's being used

37
00:01:58,680 --> 00:02:01,210
inside your phone to figure out which orientation it's in.

38
00:02:01,209 --> 00:02:06,034
Its exactly the process being used inside a drone to figure out altitude and position.

39
00:02:06,034 --> 00:02:08,759
This non-linear least square estimation is

40
00:02:08,759 --> 00:02:12,254
another idea that is very much core to the estimation process.

41
00:02:12,254 --> 00:02:14,280
The one thing you might be seeing as well,

42
00:02:14,280 --> 00:02:16,270
we made an assumption the vehicle is not moving.

43
00:02:16,270 --> 00:02:18,060
In the next couple of lessons,

44
00:02:18,060 --> 00:02:21,584
we're going to look at how specific sensors can plug into this formulation,

45
00:02:21,584 --> 00:02:24,780
and we'll look at how to relax that last assumption

46
00:02:24,780 --> 00:02:28,520
about the vehicle moving using something called the common filter.

